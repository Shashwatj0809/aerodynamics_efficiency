# -*- coding: utf-8 -*-
"""TestData.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_u-m1xnabYMTWCAg4bvQnKTukyTA49Ig
"""

# 📦 1. Install packages (Uncomment when needed in Colab)
# !pip install xgboost scikit-learn pandas matplotlib seaborn -q

# 📌 2. Import libraries
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import mean_squared_error, r2_score, f1_score
from sklearn.preprocessing import StandardScaler, KBinsDiscretizer

# 📂 3. Load dataset
df = pd.read_csv('/content/DrivAerNet_F1Optimized.csv')

# 🧠 4. Feature Engineering
df['Body_Surface_Ratio'] = df['A_Car_Roof_Height'] / df['A_Car_Width']
df['Greenhouse_Ratio'] = df['A_Car_Green_House_Angle'] / (df['A_Car_Length'].replace(0, np.nan))
df['Combined_Inclination'] = df['D_Rear_Window_Inclination'] + df['D_Winscreen_Inclination']
df['Aerodynamic_Blend_Factor'] = df['B_Ramp_Angle'] + df['B_Diffusor_Angle'] + df['B_Trunklid_Angle']
df['Speed_Diffusor_Product'] = df['Speed_kmph'] * df['B_Diffusor_Angle']
df['Length_Width_Ratio'] = df['A_Car_Length'] / df['A_Car_Width'].replace(0, np.nan)

# Clean-up
df.replace([np.inf, -np.inf], np.nan, inplace=True)
df.fillna(0, inplace=True)

# 🎯 5. Define input features and targets
features = [
    'Speed_kmph', 'B_Ramp_Angle', 'B_Diffusor_Angle', 'A_Car_Length', 'Reynolds_Number',
    'Body_Surface_Ratio', 'Greenhouse_Ratio', 'Combined_Inclination',
    'Aerodynamic_Blend_Factor', 'Speed_Diffusor_Product', 'Length_Width_Ratio'
]
target_drag = 'Average Cd'
target_downforce = 'Ideal_Downforce'

X = df[features]
y_cd = df[target_drag]
y_downforce = df[target_downforce]

# 🧼 6. Scale inputs
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# 📤 7. Train/test split
X_train, X_test, y_cd_train, y_cd_test = train_test_split(X_scaled, y_cd, test_size=0.2, random_state=42)
_, _, y_df_train, y_df_test = train_test_split(X_scaled, y_downforce, test_size=0.2, random_state=42)

# 🌲 8. Train base models
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_cd_train)
rf_preds = rf_model.predict(X_test)

xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)
xgb_model.fit(X_train, y_cd_train)
xgb_preds = xgb_model.predict(X_test)

# 📈 9. Evaluate - R2 for Regression
print("🔹 Random Forest R²:", r2_score(y_cd_test, rf_preds))
print("🔹 XGBoost R²:", r2_score(y_cd_test, xgb_preds))

# 🎯 10. Optional: Downforce → classification for F1 Score
bins = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='quantile')
y_df_train_cls = bins.fit_transform(y_df_train.values.reshape(-1, 1)).ravel()
y_df_test_cls = bins.transform(y_df_test.values.reshape(-1, 1)).ravel()

rf_cls = RandomForestRegressor()
rf_cls.fit(X_train, y_df_train_cls)
y_cls_pred = np.round(rf_cls.predict(X_test)).astype(int)
print("🔹 F1 Score (Downforce Class):", f1_score(y_df_test_cls, y_cls_pred, average='weighted'))

# 🔍 11. Hyperparameter Tuning
param_grid = {
    'n_estimators': [50, 100],
    'max_depth': [None, 10, 20],
}
grid = GridSearchCV(RandomForestRegressor(random_state=42), param_grid, cv=3, scoring='r2')
grid.fit(X_train, y_cd_train)
print("🔧 Best Params (Cd Prediction):", grid.best_params_)
print("🔧 Best R² Score:", grid.best_score_)

# 📤 12. Predict Ideal Setup
def get_ideal_setup(speed_kmph, ramp_angle, diffusor_angle, car_length):
    reynolds = (1.225 * (speed_kmph * 1000 / 3600) * 1.7) / (1.81e-5)
    trunklid_angle = 0  # Assume average if not known
    rear_window = 2     # Assume average if not known
    winscreen = 2       # Assume average if not known
    car_width = 110     # Approximate average
    roof_height = 20    # Approximate average
    greenhouse_angle = 50  # Average guess

    # Derived features
    body_surface_ratio = roof_height / car_width
    greenhouse_ratio = greenhouse_angle / car_length
    combined_inclination = rear_window + winscreen
    aero_blend = ramp_angle + diffusor_angle + trunklid_angle
    speed_diffusor = speed_kmph * diffusor_angle
    len_width_ratio = car_length / car_width

    input_data = pd.DataFrame([[
        speed_kmph, ramp_angle, diffusor_angle, car_length, reynolds,
        body_surface_ratio, greenhouse_ratio, combined_inclination,
        aero_blend, speed_diffusor, len_width_ratio
    ]], columns=features)

    input_scaled = scaler.transform(input_data)
    pred_cd = grid.predict(input_scaled)[0]
    pred_df = rf_cls.predict(input_scaled)[0]
    levels = ['Low', 'Medium', 'High']

    print(f"\n🧠 Ideal Predictions for Speed={speed_kmph} km/h:")
    print(f"   ➤ Predicted Drag Coefficient (Cd): {pred_cd:.4f}")
    print(f"   ➤ Estimated Downforce Level: {levels[int(pred_df)]}")

    if speed_kmph > 300:
        print("   🔧 Suggestion: Keep wing angle low for less drag (straight)")
    elif 150 < speed_kmph <= 300:
        print("   🔧 Suggestion: Moderate wing angle, optimize for balance")
    else:
        print("   🔧 Suggestion: Increase wing angle for maximum downforce (turns)")

# ✅ 13. Try Example Runs
get_ideal_setup(speed_kmph=320, ramp_angle=5, diffusor_angle=6, car_length=30)
get_ideal_setup(speed_kmph=120, ramp_angle=9, diffusor_angle=10, car_length=28)

# 📊 14. Combined Plot: Drag Coefficient vs Downforce (on test data)
plt.figure(figsize=(12, 6))
plt.plot(y_cd_test.values, label='Actual Cd', linestyle='--', color='blue')
plt.plot(rf_preds, label='Predicted Cd', color='navy')
ax1 = plt.gca()
ax2 = ax1.twinx()
ax2.plot(y_df_test.values, label='Actual Downforce', linestyle='--', color='orange')
ax2.plot(rf_cls.predict(X_test), label='Predicted Downforce', color='darkorange')
lines_1, labels_1 = ax1.get_legend_handles_labels()
lines_2, labels_2 = ax2.get_legend_handles_labels()
plt.title('📊 Drag Coefficient vs Downforce (Test Data)')
ax1.set_ylabel('Drag Coefficient (Cd)', color='blue')
ax2.set_ylabel('Downforce', color='orange')
ax1.set_xlabel('Test Samples')
ax1.legend(lines_1 + lines_2, labels_1 + labels_2, loc='upper right')
plt.grid(True)
plt.tight_layout()
plt.show()

# 📈 15. Telemetry Analysis: Feature vs Target Relationships
fig, axes = plt.subplots(3, 4, figsize=(20, 12))
axes = axes.flatten()

for i, feature in enumerate(features):
    sns.scatterplot(data=df, x=feature, y=target_drag, ax=axes[i], color='blue', label='Cd')
    sns.scatterplot(data=df, x=feature, y=target_downforce, ax=axes[i], color='orange', label='Downforce')
    axes[i].set_title(f"{feature} vs Cd & Downforce")
    axes[i].legend()
    axes[i].grid(True)

plt.suptitle("📈 Telemetry Feature Analysis: Impact on Cd and Downforce", fontsize=16)
plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.show()

pip install fastf1

import os
import fastf1
from fastf1 import plotting
from fastf1.core import Laps
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# ✅ Create cache folder if it doesn't exist
os.makedirs('./f1_cache', exist_ok=True)

# ✅ Enable cache
fastf1.Cache.enable_cache('./f1_cache')


# Load a race session
session = fastf1.get_session(2023, 'Monza', 'R')
session.load(telemetry=True)

# Define required telemetry columns (fixed: 'Gear' → 'nGear')
required_cols = ['Speed', 'nGear', 'Throttle', 'Brake']

# Define ideal values from trained model
ideal_values = {
    'Straight': {'Speed': 320, 'nGear': 8, 'Throttle': 1.0, 'Brake': 0.0},
    'Low-Speed Turn': {'Speed': 160, 'nGear': 3, 'Throttle': 0.5, 'Brake': 0.5},
    'Medium-Speed Turn': {'Speed': 180, 'nGear': 5, 'Throttle': 0.7, 'Brake': 0.3}
}

# Container to collect data
telemetry_comparison = []

# Get all laps
laps = session.laps.pick_quicklaps()

# Iterate through drivers
for drv in session.drivers:
    drv_laps = laps.pick_driver(drv)

    if drv_laps.empty:
        continue

    team = drv_laps.iloc[0]['Team']

    try:
        fastest_lap = drv_laps.pick_fastest()
        telemetry = fastest_lap.get_car_data().add_distance()
    except:
        print(f"⚠️ Skipping {team} due to missing telemetry")
        continue

    # Check if required columns exist
    if not all(col in telemetry.columns for col in required_cols):
        print(f"⚠️ Skipping {team} due to missing telemetry data.\nColumns present: {telemetry.columns}")
        continue

    # Compute averages
    avg_speed = telemetry['Speed'].mean()
    avg_gear = telemetry['nGear'].mean()
    avg_throttle = telemetry['Throttle'].mean()
    avg_brake = telemetry['Brake'].mean()

    # Compare with ideal values
    for turn_type, ideal in ideal_values.items():
        telemetry_comparison.append({
            'Team': team,
            'Turn Type': turn_type,
            'Speed Diff': abs(avg_speed - ideal['Speed']),
            'Gear Diff': abs(avg_gear - ideal['nGear']),
            'Throttle Diff': abs(avg_throttle - ideal['Throttle']),
            'Brake Diff': abs(avg_brake - ideal['Brake'])
        })

# Convert to DataFrame
telemetry_df = pd.DataFrame(telemetry_comparison)

# Show sample
print("✅ Columns in telemetry_df:", telemetry_df.columns)
print("📊 Sample data:")
print(telemetry_df.head())

# If empty, warn and skip plotting
if telemetry_df.empty:
    print("❌ No valid telemetry data available for plotting.")
else:
    # Plot speed difference
    plt.figure(figsize=(12, 6))
    sns.barplot(data=telemetry_df, x='Team', y='Speed Diff', hue='Turn Type')
    plt.title("Speed Difference from Ideal in Different Turn Types")
    plt.ylabel("Difference (km/h)")
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

